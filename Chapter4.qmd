---
title: "Chapter 4"
format: 
  html:
    code-fold: false
    code-tools: true
editor: source
author: Lilla Gurtner
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = F, message = F, error=F, include = F}

# knitr global options ----
knitr::opts_chunk$set(fig.pos = 'H',
                      echo = T,
                      message = F,
                      warning = F, 
                      dpi = 600,
                      fig.align = "center", 
                      fig.asp = 0.62) # golden ratio

library(tidyverse)
library(tidybayes) # nice ploting
library(brms)
library(wesanderson)

theme_set(theme_tidybayes())

```

# 4E1. 

In the model definition below, which line is the likelihood? 

*yi ∼ Normal(μ, σ)*

μ ∼ Normal(0, 10) 

σ ∼ Exponential(1)

# 4E2. 

In the model definition just above, how many parameters are in the posterior distribution?

=> 2


# 4E3. 

Using the model definition above, write down the appropriate form of Bayes’ theorem that includes the proper likelihood and priors.


\[
\Pr(\mu, \sigma \mid y_{i}) = \frac{\prod_i \text{Normal}(y_i \mid \mu, \sigma) \text{Normal}(\mu \mid 0, 10) \text{Exponential}(\sigma \mid 1)}{\int \int \prod_i \text{Normal}(y_i \mid \mu, \sigma) \text{Normal}(\mu \mid 0, 10) \text{Exponential}(\sigma \mid 1) \, d\mu \, d\sigma}
\]


# 4E4. 

In the model definition below, which line is the linear model? 

yi ∼ Normal(μ, σ) 

*μi = α + βxi*

α ∼ Normal(0, 10) 

β ∼ Normal(0, 1) 

σ ∼ Exponential(2)


# 4E5. 

In the model definition just above, how many parameters are in the posterior distribution?

=> 3



# 4M1. 
For the model definition below, simulate observed y values from the prior (not the posterior). 

yi ∼ Normal(μ, σ) 
μ ∼ Normal(0, 10) 
σ ∼ Exponential(1)

```{r}

n_values <- 1000
sigma <- rexp(n_values, rate = 1)
mu <- rnorm(n_values, mean = 0, sd = 10)

y <- rnorm(n_values, mu, sigma)

hist(y)
```


# 4M2
Translate the model just above into a quap formula. (and also doing brms formula)

```{r}

# quap: 
flist <- alist( y_i ~ dnorm( mu , sigma ) , 
                mu ~ dnorm( 0 , 10 ) , 
                sigma ~ exp( 1 ) )


# brms model fitting & parameter recovery


library(brms)
formula <- bf(outcome ~ 1)

prior <- c(prior(normal(0,0.1), class = Intercept),
           prior(exponential(1), class = sigma))
  

test_data <- tibble(
  outcome = rnorm(100, mean = 2, sd = 2)
                    )

test_model_100 <- brm(formula = formula, 
                  family = gaussian(), 
                  prior = prior, 
                  data = test_data, 
                  sample_prior = T)

plot(test_model_100)

a <- test_model_100 |> tidybayes::spread_draws(b_Intercept, sigma)

hist(a$b_Intercept)
hist(a$sigma)


test_data <- tibble(
  outcome = rnorm(10000, mean = 2, sd = 2)
                    )

test_model_10000 <- brm(formula = formula, 
                  family = gaussian(), 
                  prior = prior, 
                  data = test_data, 
                  sample_prior = T)

plot(test_model_10000)

a <- test_model_10000 |> spread_draws(b_Intercept, sigma)

hist(a$b_Intercept)
hist(a$sigma)


```


# 4M4. 
A sample of students is measured for height each year for 3 years. After the third year, you want to fit a linear regression predicting height using year as a predictor. Write down the mathematical model definition for this regression, using any variable names and priors you choose. Be prepared to defend your choice of priors.


height[i] ~ normmal(mu, sigma)

mu ~ a + b*year

a ~ normal(135, 10) (assuming children, aged 10)
b ~ normal(mean = 20, sd = 4) & no value below 0 OR: 
b ~ lognormal(0,1)
sigma ~ exponential(1)


```{r}
a <- rnorm(1000, mean = 135, sd = 10)
hist(a)

b <- rnorm(1000, mean = 20, sd = 4)
  
hist(b)

c <- rexp(1000, 0.1)
hist(c)


data <- tibble(x = seq(from = 0.0000001, to = 10, by = 0.01), 
               y_1 = exp(-x), 
               y_01 = 0.1*exp(-0.1*x), 
               y_5 = 5*exp(-5*x))
               
               
               rexp(x, rate = 5))

data |> ggplot(aes(x = x, y = y_1)) + 
  geom_line() + 
  geom_line(aes(y = y_01), color = "red") + 
  geom_line(aes(y = y_5), color = "green")






```


# 4M5
Now suppose I remind you that every student got taller each year. Does this information lead you to change your choice of priors? How?

=> no, bc I thought of that before

# 4M6
Now suppose I tell you that the variance among heights for students of the same age is never more than 64cm. How does this lead you to revise your priors?

```{r}
a <- rexp(1000, rate = 0.1)

mode_hdi(a)
hist(a)

```

=> not much changes. with exp(1), the value of sigma being above 64 is practically zero. the rate would have to be 0.049 to move the 64cm within the mode_hdi of the prior. 



# 4M7

Refit model m4.3 from the chapter, but omit the mean weight xbar this time. Compare the new model’s posterior to that of the original model. In particular, look at the covariance among the parameters. What is different? Then compare the posterior predictions of both models.

```{r}
d_fit <- d2 |> 
  mutate(mean_weight = mean(weight),
         centered_weight = weight - mean_weight
         )

m4.3_original <- brm(height ~ 1 + centered_weight, 
                     family = gaussian, 
                     data = d_fit, 
                     prior = c(prior(normal(178,20), class = Intercept),
                               prior(normal(0, 10), class = b),
                               prior(uniform(0, 50), class = sigma, ub = 50)),
                     iter = 6000, 
                     warmup = 3000, 
                     init = 0,
                     chains = 4, 
                     cores = 4,
                     seed = 4,
                     file = "fits/b04.03")

  

  
m4.3_original_2 <- brm(height ~ 1 + weight, 
                     family = gaussian, 
                     data = d_fit, 
                     prior = c(prior(normal(178,20), class = Intercept),
                               prior(normal(0, 10), class = b),
                               prior(uniform(0, 50), class = sigma, ub = 50)),
                     iter = 6000, 
                     warmup = 3000, 
                     init = 0,
                     chains = 4, 
                     cores = 4,
                     seed = 4,
                     file = "fits/b04.03b")

  as_draws_df(m4.3_original) %>%
  select(b_Intercept:sigma) %>%
  cor() %>%
  round(digits = 2)
  
  as_draws_df(m4.3_original_2) %>%
  select(b_Intercept:sigma) %>%
  cor() %>%
  round(digits = 2) # high correlation between intercept and b
  
  
  plot(m4.3_original) 
  plot(m4.3_original_2) # intecept from the uncentered is lower
  
  
```



# 4H1
The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals for each of these individuals. That is, fill in the table below, using model-based predictions. Individual weight expected height 89% interval 1 46.95 2 43.72 3 64.78 4 32.59 5 54.63

```{r}

dat <- tibble(centered_weight = c(46.95, 43.72, 64.78, 32.59, 54.63))


# i take the orginal model from above

samples_model_original <- tidy_draws(m4.3_original) |> 
  mutate(pred1 = rnorm(n = n(), mean =  b_Intercept + b_centered_weight*46.95, sd = sigma), 
         pred2 = rnorm(n = n(), mean =  b_Intercept + b_centered_weight*43.72, sd = sigma), 
         pred3 = rnorm(n = n(), mean =  b_Intercept + b_centered_weight*64.785, sd = sigma), 
         pred4 = rnorm(n = n(), mean =  b_Intercept + b_centered_weight* 32.5, sd = sigma), 
         pred5 = rnorm(n = n(), mean =  b_Intercept + b_centered_weight*54.63, sd = sigma)
         )

result <- samples_model_original |> 
  select(starts_with("pred")) |> 
  pivot_longer(1:5, names_to = "person", values_to = "height_pred") |> 
  group_by(person) 


result |> 
  ggplot(aes(x = height_pred)) + geom_density() + facet_grid(. ~ person)



pred_height <-
  predict(m4.3_original,
          newdata = dat, summary = T)
%>%
  as_tibble()
%>%
  bind_cols(weight_seq)
  
```



# 4H2. 

Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it. 

(a) Fit a linear regression to these data, using quap. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets? 

(b) Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Superimpose the MAP regression line and 89% interval for the mean. Also superimpose the 89% interval for predicted heights. 

(c) What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don’t have to write any new code. 

- the lower and upper hights are not fitted well by this model, the middle part seems to be ok. 
- parameter correlation seems to be ok. 
- probably splines would do better, one with a knot at mu-12 and then one at mu+12, or a thrid grade polinomial



```{r}

d_kids <- d |> 
  filter(age < 18) |>  # correct
  mutate(mean_weight = mean(weight),
         centered_weight = weight - mean_weight
         )

hist(d_kids$weight)
# a)
m4.3_kids <- brm(height ~ 1 + centered_weight, 
                     family = gaussian, 
                     data = d_kids, 
                     prior = c(prior(uniform(0, 200), class = Intercept, lb = 0),
                               prior(normal(0, 10), class = b),     
                               # Franca 155 => 40kg , Emil 145 => 30
                               prior(uniform(0, 50), class = sigma, ub = 50)),
                     iter = 6000, 
                     warmup = 3000, 
                     init = 0,
                     chains = 4, 
                     cores = 4,
                     seed = 4,
                     file = "fits/b04.03_kids")

 as_draws_df(m4.3_original) %>%
  select(b_Intercept:sigma) %>%
  cor() %>%
  round(digits = 2)

# plotting 
 weight_seq <- tibble(centered_weight = seq(from = -20, to = 30, by = 1))

pred_height <-
  predict(m4.3_kids,
          newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq) |> 
  rename(height = Estimate)

mu_summary <- fitted(m4.3_kids, 
         newdata = weight_seq) %>%
  as_tibble() %>%
  # let's tack on the `weight` values from `weight_seq`
  bind_cols(weight_seq)

d_kids |> 
  ggplot(aes(x = centered_weight, y = height)) + 
  
  geom_ribbon(data = pred_height, 
              aes(ymin = Q2.5, ymax = Q97.5), 
              fill = "grey83") + 
  geom_smooth(data = mu_summary,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "grey70", color = "black", alpha = 1, linewidth = 1/2) +
  geom_point(alpha = 0.2) 








```


